# ✨天眼搜索引擎设计文档

天眼搜索引擎各模块如下：

- 爬虫

  每天不间断（好吧其实是根据配置里面的深度来的）上网获取数据并将其保存到数据库。

- 反向索引构建器

  将数据库里面的数据分割为关键词并整理构建反向索引。

- 反向链接整理器

  用于统计整理链接的被其他链接所链的度，我称其为繁荣度，即一个链接存在于其他链接下的度

- 任务管理器

  用于管理定时服务的触发。

- 后端服务

  本地开放一个端口，可以从这里请求到数据。

- 前端

  搜索引擎的前端界面

### 🎁爬虫

你知道数据结构里面的“图”吗？是的，跟这个关系不大（笑），当然知道更好。

爬虫模块主要是一个广度优先遍历（BFS），对根站进行一个target_depth深度的遍历。

将整体视为一张有向图，根站即为有向图根节点，然后从根节点上面获取每一个子节点（a标签元素），然后获取这些节点的信息并将它们保存到数据库

### 🎉反向索引构建器

反向索引从数据库里取得爬虫获得的信息，并分割出关键词并生成索引，并将索引保存至数据库。

### 反向链接整理器

href为键，由域名构成的列表为值。整理出一个href由哪些链接所引用，以这些链接的域名为键值，通过所有域名的均值对href进行加权。

### 🎀任务管理器

用于管理定时任务的触发。

### 🎈后端服务

即本地开放一个端口，用于获得数据。

使用方法：发送**post请求http://127.0.0.1:1314/search?q={q}**

当然，端口号是根据配置文件里面的端口来定的。

### 🧨前端

提供前端界面，获取从输入框输入的词，并向后端服务发送一个请求，将后端返回的数据进行处理最终显示在界面上。

## 🎊各文件说明

- spider.py

  存放了爬虫程序的主要函数，多数需requests的函数也在这个文件

- mongodb.py

  存放数据库操作函数

- server.py

  后端服务器

- database.py

  数据库

- config.py

  配置文件

- log_lg.py

  输出logo

- manage.py

  定时任务管理

- data_process.py

  数据处理的函数

- utils.py

  存放一些公共函数

- lid.176.ftz

  语言检测模型
